# Natwest-s-Hack-Back-off

**MODULE:**
  **1. Person Classification:** In this module, we are leveraging a pre-trained Vision Transformer (ViT) model that has been fine-tuned using Masked Autoencoding (MAE) and InfoNCE loss techniques. The model is further employed for person classification tasks, capitalizing on the learned representations to enhance classification accuracy and robustness. This approach allows us to benefit from state-of-the-art transformer architecture while utilizing self-supervised learning strategies for improved feature extraction.

**2. Audio Deepfake Detection:** In this module, we are building a generalized and robust model to detect audio deepfakes, with a specific focus on spoofing detection. The approach is designed to identify synthetic or manipulated audio used in malicious activities. To develop this solution, we are referring to recent advancements and research from the ASVspoof Challenge, which provides a benchmark for anti-spoofing systems. Our model aims to tackle various types of audio attacks while maintaining high accuracy and generalizability across different environments and audio conditions.

**Additional Features:** 

1. Cross-Modality Learning: By combining insights from both image and audio deepfake detection, our system is designed to ensure comprehensive integrity checks across multiple media formats.

2. Real-time Detection: The system will be optimized for real-time detection, ensuring swift responses to potential threats in both images and audio streams.

